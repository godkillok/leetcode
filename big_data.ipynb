{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 数据结构：\n",
    "\n",
    "参考文献  \n",
    "http://blog.sina.com.cn/s/blog_a0db4ee90102vrzk.html\n",
    "https://www.cnblogs.com/shawshawwan/p/9500952.html\n",
    "\n",
    "https://blog.csdn.net/codercong/article/details/52065151\n",
    "\n",
    "【Bloom Filter】\n",
    "\n",
    "  它实际上是一个很长的二进制向量和一系列随机映射函数\n",
    "\n",
    "  布隆过滤器可以用于检索一个元素是否在一个集合中\n",
    "\n",
    "  它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难\n",
    "\n",
    " \n",
    "\n",
    "【Bit map】\n",
    "\n",
    "  Bit-map就是用一个bit位来标记某个元素对应的Value， 而Key即是该元素。由于采用了Bit为单位来存储数据，因此在存储空间方面，可以大大节省\n",
    "  \n",
    "**应用1：大数据求交**\n",
    "现有两个各有20亿行的文件，每一行都只有一个数字，求这两个文件的交集。  \n",
    "因为int的最大数是2^32 - 1 == 约43亿，用一个二进制的下标来表示一个int值，大概需要43亿个bit位，即约43亿/8 = 5.4亿Byte，即约540M的内存。这可以解决问题了。\n",
    "\n",
    "1.首先遍历文件，将每个文件按照数字的正数，负数标记到2个BitSet上为：正数BitSetA_positive，负数BitSetA_negative\n",
    "\n",
    "2.遍历另为一个文件，生成正数：BitSetB_positive ,BitSetB_negative\n",
    "\n",
    "3.取BitSetA_positive and BitSetB_positive 得到2个文件的正数的交集，同理得到负数的交集。\n",
    "\n",
    "4.合并，问题解决。\n",
    "\n",
    "**应用2：大数据 distict count**\n",
    "  \n",
    "已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。\n",
    " 每一个电话号码被映射到了不同的位。\n",
    "\n",
    "例如：\n",
    "\n",
    "61234567 对应位 0x00001000\n",
    "\n",
    "61234568 对应位 0x0001 0000\n",
    "\n",
    "这样，每一个电话号码也就有了它自己的唯一标识，而且这个标识只占用1位，如果电话号码被统计过，这个位就标识为1，否则标识为0。电话号码不就是1这个数字左移位所应该对应的次数么。\n",
    "\n",
    "最后，通过统计bitmap中被标记为1的个数，就能统计出来不同号码的个数。\n",
    "\n",
    "**应用3：统计日活**\n",
    "\n",
    "将用户映射到bitmap 的某一位上，日活了就在指定位置上变成1，这样对位图计数就可以了。也可以和其他指标做join 统计，直接用bit 里的and 就可以了。\n",
    "\n",
    "**应用4：排序(重大缺陷就是要知道最大值是多少，否则怎么分配设计map )**\n",
    "\n",
    "所谓的Bit-map就是用一个bit位来标记某个元素对应的Value， 而Key即是该元素。由于采用了Bit为单位来存储数据，因此在存储空间方面，可以大大节省。\n",
    "　　如果说了这么多还没明白什么是Bit-map，那么我们来看一个具体的例子，假设我们要对0-7内的5个元素(4,7,2,5,3)排序（这里假设这些元素没有重复）。那么我们就可以采用Bit-map的方法来达到排序的目的。要表示8个数，我们就只需要8个Bit（1Bytes），首先我们开辟1Byte的空间，将这些空间的所有Bit位都置为0\n",
    "　　然后遍历这5个元素，首先第一个元素是4，那么就把4对应的位置为1。\n",
    "　　然后再处理第二个元素7，将第八位置为1,，接着再处理第三个元素，一直到最后处理完所有的元素，将相应的位置为1。\n",
    "\n",
    "　　然后我们现在遍历一遍Bit区域，将该位是一的位的编号输出（2，3，4，5，7），这样就达到了排序的目的\n",
    "  \n",
    "**应用5 整数去重**\n",
    " 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。  \n",
    "思路1：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。\n",
    "（也就是不管有没有先生成1GB的bitmap，然后再挨个挨个去改状态，然后再收集回状态有问题的整数）\n",
    "思路2：\n",
    "总共大小2.5*10^8*4字节=1G\n",
    "（1）将这么多整数先hash(val)00分成1000个小文件，相同的数就在相同的文件中\n",
    "（2）对每个小文件进行hash映射，统计出现次数，然后将对应次数为1的输出。\n",
    "\n",
    " \n",
    "【Hash】\n",
    "\n",
    "5、 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？\n",
    "\n",
    "思路：每个文件的大小5G*64 = 32G，远远大于内存，需要对a，b分别分成小文件\n",
    "\n",
    "（1）利用一个hash(url)00，分别将a，b文件分别映射成1000个小文件，因为通过相同的映射函数，所以对于a，b，相同的url都在对应的文件中，（a0 vs b0, a1 vs b1等等）\n",
    "\n",
    "（2）分别比对这1000个对应的小文件，可以通过先将a映射到一个hash表中，然后依次遍历b，判断是否在a中出现，出现过则说明重复\n",
    "\n",
    "怎么在海量数据中找出重复次数最多的一个？\n",
    "\n",
    "思路：hash分成小文件，分别统计每个小文件数据出现次数，找出出现次数最大的，然后在将每个小文件的最大值进行比较，找到最大值，与上面思路一样的。\n",
    "\n",
    "\n",
    "【Trie】\n",
    "\n",
    "　　1).有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。\n",
    "\n",
    "　　2).1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？\n",
    "\n",
    "　　3).寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。\n",
    "  \n",
    "【堆】\n",
    "\n",
    "\n",
    "## 常见思想：\n",
    "\n",
    "**【分而治之/hash映射 + hash统计 + 堆/快速/归并排序】**\n",
    "\n",
    " 对大文件使用hash取模映射成小文件，再在小文件中分别统计。\n",
    " \n",
    "**例1:  海量日志数据，提取出某日访问百度次数最多的那个IP**\n",
    "\n",
    "（文件总量多大 -> 能一次载入内存吗 -> 怎么将文件化大为小，一般可以采取hash -> 然后怎么归并）\n",
    "\n",
    "首先可以估计下某天全部的日志大小，当然可以选取任一个合理的估计 ，而不需要很精确。比如IP总的可能情况是？\n",
    "\n",
    "解答思路：  \n",
    "1.IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中处理；  \n",
    "2.可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址；   \n",
    "3.对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址；  \n",
    "4.可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP\n",
    "\n",
    "\n",
    "**例2: 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。\n",
    "假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门），请你统计最热门的10个查询串，要求使用的内存不能超过1G**\n",
    "\n",
    "\n",
    "1.hash_map统计：先对这批海量数据预处理。具体方法是：维护一个Key为Query字串，Value为该Query出现次数的HashTable，即hash_map(Query，Value)，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终我们在O(N)的时间复杂度内用Hash表完成了统计；\n",
    "\n",
    "2.堆排序：第二步、借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。即借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。所以，我们最终的时间复杂度是：O（N） + N' * O（logK），（N为1000万，N’为300万）\n",
    "\n",
    "\n",
    "**例3: 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词**  \n",
    "分而治之 + hash统计 + 堆/快速排序\n",
    "\n",
    "1.分而治之/hash映射：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。  \n",
    "2.hash_map统计：对每个小文件，采用trie树/hash_map等统计每个文件中出现的词以及相应的频率。  \n",
    "3.堆/归并排序：取出出现频率最大的100个词（可以用含100个结点的最小堆）后，再把100个词及相应的频率存入文件。类似的做法处理原始的5000个文件，那么这样又得到了5000个结果文件（每个结果文件记录了频率最高的100）。最后就是把这5000个文件进行归并（类似于归并排序）的过程了。  （A、感觉这一步都不用啥排序，就直接维护一个队列，长度就是topn，比最小的都小，就不用进队列。如果大就用特殊算法，快速找到合适它的位置，并把最小的剔除队列。难道这个就是归并算法么？？B、这种做法的前提条件一定是同一个单词只出现在一个文件中，如果可能出现在多个文件就乱套了） \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "**【双层桶划分】**\n",
    "事实上，与其说双层桶划分是一种数据结构，不如说它是一种算法设计思想。面对一堆大量的数据我们无法处理的时候，我们可以将其分成一个个小的单元，然后根据一定的策略来处理这些小单元，从而达到目的。  \n",
    "\n",
    "\n",
    "**适用范围**  \n",
    "第k大，中位数，不重复或重复的数字\n",
    "\n",
    "**应用1：不重复的数**\n",
    "1).2.5亿个整数中找出不重复的整数的个数，内存空间不足以包容这2.5亿个整数。\n",
    "\n",
    "整数个数为2^32,也就是，我们可以将这2^32个数划分为2^8个区域，然后不同的区域在使用bitmap等方式处理了。也可以直接用bitmap处理，每两个bit位表示一个整数，00表示整数未出现，01表示出现一次，10表示出现两次及其以上。\n",
    "\n",
    "**应用2：中位数，第K位数**  \n",
    "2).5亿个int找它们的中位数。\n",
    "\n",
    "我们将int分别为2^16个地区，然后读取数据统计落到各个地区里的数的个数，以后我们凭据统计成果就能够判定中位数落到哪个区域，同时晓得这个区域中的第几大数恰好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数便可以了。 （应该类似于分段，例如1-100 有重复的数，分成10段。那么第一段是1-10，也就是意味1-10的都在落在这个段落里，同理第二段是11-20....。那么就可以得到一个统计，1-10的有40个,11-20的20个，那么就很显然了第50个一定是11-20，那么就好好的排下11-20，而且是可以精确的知道1-10是40个，那么排名倒数10的就是了）  \n",
    "**中位数和第K位数都是排序问题，把排序问题先转为了计数问题，然后再小范围排序**\n",
    "\n",
    " \n",
    "\n",
    "3).此刻有一个0-30000的随机数生成器。请凭据这个随机数生成器，计划一个抽奖范围是0-350000彩票中奖号码列表，个中要包括20000其中奖号码。\n",
    "\n",
    "一个0到3万的随机数生成器要生成一个0到35万的随机数。那么我们完整可以将0-35万的区间分成35/3=12个区间，然后每一个区间的长度都小于3万，我们就可以用问题给的随机数生成器来生成为了，然后再加之该区间的基数。每一个区间要生成的随机数个数：区间长度*随机数密度，30000*（20000/350000），然后如果第一个1区间那么基数就是0，则随机数=基数+该区间的生成的随机数，第二个区间的那么就是3W，则随机数就是3W+该区间的生成的随机数...\n",
    "\n",
    "\n",
    "【Trie树/数据库/倒排索引】\n",
    "Trie树（数据量大，重复多，但是数据种类小可以放入内存）  \n",
    "数据库（适用范围：大数据量的增删改查）  \n",
    "倒排索引（适用范围：搜索引擎，关键字查询）  \n",
    "\n",
    "【外排序】\n",
    "\n",
    "【分布式处理之Hadoop/Mapreduce】\n",
    "\n",
    "【其他】\n",
    "100w个数中找出最大的100个数。\n",
    "\n",
    "思路1：最小堆，找最大100个数\n",
    "\n",
    "思路2：快速排序，每次分割之后只考虑比轴大的一部分（快速选择的思想），直到比轴大的一部分比100多时，采用传统排序，取前100个\n",
    "\n",
    "思路3：选取前100个元素，排序，然后扫描剩余的元素，与排好序的元素中最小的相比，如果比它大，替换，重排前面，这跟堆排序思路一样。\n",
    "\n",
    "\n",
    "## 总结：\n",
    "\n",
    "\n",
    "这些海量数据处理的题，思路基本差不多，首先是hash映射，成为不同类型的文件,然后hash统计，之后进行排序等等。以下是july总结的，以上也是参考其中博客整理一些思路的产物。：\n",
    "         \n",
    "+ 分而治之/hash映射 + hash统计 + 堆/快速/归并排序（频率最高，最大等）；\n",
    "+ 双层桶划分（中位数， 不重复数）：本质上还是分而治之的思想，重在“分”的技巧上！\n",
    "适用范围：第k大，中位数，不重复或重复的数字\n",
    "+ Bloom filter/Bitmap（可以用来实现数据字典，进行数据的判重，或者集合求交集，不重复数）；\n",
    "+ Trie树（数据量大，重复多，但是数据种类小可以放入内存）/数据库（适用范围：大数据量的增删改查）/倒排索引（适用范围：搜索引擎，关键字查询）；\n",
    "+ 外排序：大数据排序，去重，外部排序的归并算法，置换选择败者树原理，最优归并数\n",
    "+ 分布式处理之Hadoop/Mapreduce：数据量大，但数据种类小可以放入内存，将数据交给不同的机器去处理，数据划分，结果规约\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  spark 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
